{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865e4708-4c8b-484e-aae9-173b8206a79f",
   "metadata": {},
   "source": [
    "## MultiOutput pickle Random Forest with spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b0e147-2d34-49c1-a31b-5bb3008259b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d96cec9-7c15-4b61-8b26-b74f1b72e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets are downloable at:\n",
    "# https://www.kaggle.com/landlord/multilingual-disaster-response-messages\n",
    "# Importing disaster messages data\n",
    "df = pd.read_csv('../datasets/df_clean.csv')\n",
    "df.drop(columns = ['Unnamed: 0', 'content_length', 'content_word_count', 'genre', 'related', 'PII'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10286077-de01-4db6-bda9-437caa9e5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preprocessing\n",
    "def tokenize_correct_spelling(text):\n",
    "\n",
    "    textBlb = TextBlob(text)            # Making our first textblob\n",
    "    textCorrected = textBlb.correct()   # Correcting the text\n",
    "    \n",
    "    tokens = word_tokenize(str(textCorrected))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()      \n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "# Second option for preprocessing without spelling check\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f4197f-ae85-4ee9-8f96-bb8c63c5766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning target variable\n",
    "X = df['message']\n",
    "y = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d979ee1-27fb-42ee-951b-3346eac6224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e2368e-7013-4212-ae20-2db5afbc7b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'cv', 'tfidf', 'clf', 'cv__analyzer', 'cv__binary', 'cv__decode_error', 'cv__dtype', 'cv__encoding', 'cv__input', 'cv__lowercase', 'cv__max_df', 'cv__max_features', 'cv__min_df', 'cv__ngram_range', 'cv__preprocessor', 'cv__stop_words', 'cv__strip_accents', 'cv__token_pattern', 'cv__tokenizer', 'cv__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__estimator__bootstrap', 'clf__estimator__ccp_alpha', 'clf__estimator__class_weight', 'clf__estimator__criterion', 'clf__estimator__max_depth', 'clf__estimator__max_features', 'clf__estimator__max_leaf_nodes', 'clf__estimator__max_samples', 'clf__estimator__min_impurity_decrease', 'clf__estimator__min_impurity_split', 'clf__estimator__min_samples_leaf', 'clf__estimator__min_samples_split', 'clf__estimator__min_weight_fraction_leaf', 'clf__estimator__n_estimators', 'clf__estimator__n_jobs', 'clf__estimator__oob_score', 'clf__estimator__random_state', 'clf__estimator__verbose', 'clf__estimator__warm_start', 'clf__estimator', 'clf__n_jobs'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline simple version\n",
    "multioutput_pipeline = Pipeline([\n",
    "    ('cv', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))])\n",
    "\n",
    "multioutput_pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb928f9-bf39-43df-b172-a0d36d96b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 3.66 s, total: 5min 35s\n",
      "Wall time: 5min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7f9441f184c0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "multioutput_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6513552b-175f-491f-abfa-3ad5d6152353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making preditions\n",
    "y_pred = multioutput_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3432d71a-5c4c-4be7-9826-3a219840b128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7c855-f25b-4c15-90bb-8aabcef12f69",
   "metadata": {},
   "source": [
    "### Changing your prediction threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b4b92a19-1356-48c8-9bb9-ad100dbb3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = multioutput_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cb892b04-74c0-4939-bf5b-ba14e3dc97aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5903, 35)\n"
     ]
    }
   ],
   "source": [
    "new_pred=[]\n",
    "for col in y_pred_proba:\n",
    "    new_pred.append([1 if i[0]>=0.2 else 0 for i in col] )\n",
    "new_pred = np.array(new_pred).T\n",
    "print(new_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "971b7c53-efca-46e1-bd7f-86b2098e9c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 1 1 1]\n",
      " [0 1 0 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8699fad6-c8be-4a1c-885b-f8ce0392f252",
   "metadata": {},
   "source": [
    "### Evaluating Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "16975f46-71c9-4396-b692-c52b761a10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.17      0.93      0.28      1035\n",
      "                 offer       0.00      1.00      0.01        21\n",
      "           aid_related       0.41      0.92      0.57      2562\n",
      "          medical_help       0.08      1.00      0.15       488\n",
      "      medical_products       0.05      1.00      0.10       318\n",
      "     search_and_rescue       0.03      1.00      0.05       163\n",
      "              security       0.02      1.00      0.04       106\n",
      "              military       0.03      1.00      0.06       184\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.07      0.99      0.13       404\n",
      "                  food       0.12      0.98      0.21       692\n",
      "               shelter       0.09      1.00      0.16       531\n",
      "              clothing       0.02      1.00      0.04       106\n",
      "                 money       0.02      1.00      0.05       147\n",
      "        missing_people       0.01      1.00      0.02        73\n",
      "              refugees       0.03      1.00      0.07       204\n",
      "                 death       0.05      0.99      0.09       287\n",
      "             other_aid       0.14      1.00      0.24       809\n",
      "infrastructure_related       0.07      1.00      0.13       404\n",
      "             transport       0.05      1.00      0.09       280\n",
      "             buildings       0.06      1.00      0.11       335\n",
      "           electricity       0.02      1.00      0.04       133\n",
      "                 tools       0.01      1.00      0.01        41\n",
      "             hospitals       0.01      1.00      0.02        67\n",
      "                 shops       0.00      1.00      0.01        29\n",
      "           aid_centers       0.01      1.00      0.03        76\n",
      "  other_infrastructure       0.05      1.00      0.09       285\n",
      "       weather_related       0.27      0.90      0.41      1702\n",
      "                floods       0.09      1.00      0.16       510\n",
      "                 storm       0.09      0.99      0.17       558\n",
      "                  fire       0.01      1.00      0.03        76\n",
      "            earthquake       0.09      0.86      0.16       588\n",
      "                  cold       0.02      1.00      0.04       123\n",
      "         other_weather       0.05      1.00      0.10       318\n",
      "         direct_report       0.19      0.95      0.31      1162\n",
      "\n",
      "             micro avg       0.07      0.96      0.13     14817\n",
      "             macro avg       0.07      0.96      0.12     14817\n",
      "          weighted avg       0.17      0.96      0.27     14817\n",
      "           samples avg       0.07      0.55      0.12     14817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.values, new_pred, target_names = y_test.columns.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
